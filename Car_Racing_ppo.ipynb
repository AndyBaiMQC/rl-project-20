{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "RL-Project.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNErJ6BhOJ4FU1oQA6hUoxH",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AndyBaiMQC/rl-project-20/blob/master/Car_Racing_ppo.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TneQK_gc8JoQ",
        "colab_type": "text"
      },
      "source": [
        "Reinforcement Learning (COMP-767) Project\n",
        "\n",
        "---\n",
        "\n",
        "[CarRacing-v0](https://gym.openai.com/envs/CarRacing-v0/)\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wyMV5Zzs8E7z",
        "colab_type": "code",
        "outputId": "4c949169-1f37-4f5f-bd5e-f219daadc49b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 332
        }
      },
      "source": [
        "!nvidia-smi\n",
        "!pip install box2d-py\n",
        "!pip install gym[Box_2D]\n",
        "!apt-get install x11-utils\n",
        "\n",
        "# !apt-get -qq -y install libcusparse8.0 libnvrtc8.0 libnvtoolsext1 > /dev/null\n",
        "# !ln -snf /usr/lib/x86_64-linux-gnu/libnvrtc-builtins.so.8.0 /usr/lib/x86_64-linux-gnu/libnvrtc-builtins.so\n",
        "# !apt-get -qq -y install xvfb freeglut3-dev ffmpeg> /dev/null\n",
        "# !pip -q install pyopengl pyvirtualdisplay pyglet gym\n",
        "!apt-get install -y xvfb python-opengl > /dev/null 2>&1\n",
        "!pip install gym pyvirtualdisplay > /dev/null 2>&1\n",
        "\n",
        "import gym\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython import display as ipythondisplay\n",
        "\n",
        "from pyvirtualdisplay import Display\n",
        "display = Display(visible=0, size=(400, 300))\n",
        "display.start()\n",
        "# https://stackoverflow.com/questions/50107530/how-to-render-openai-gym-in-google-colab"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "NVIDIA-SMI has failed because it couldn't communicate with the NVIDIA driver. Make sure that the latest NVIDIA driver is installed and running.\n",
            "\n",
            "Requirement already satisfied: box2d-py in /usr/local/lib/python3.6/dist-packages (2.3.8)\n",
            "Requirement already satisfied: gym[Box_2D] in /usr/local/lib/python3.6/dist-packages (0.17.1)\n",
            "\u001b[33m  WARNING: gym 0.17.1 does not provide the extra 'box_2d'\u001b[0m\n",
            "Requirement already satisfied: pyglet<=1.5.0,>=1.4.0 in /usr/local/lib/python3.6/dist-packages (from gym[Box_2D]) (1.5.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from gym[Box_2D]) (1.12.0)\n",
            "Requirement already satisfied: numpy>=1.10.4 in /usr/local/lib/python3.6/dist-packages (from gym[Box_2D]) (1.18.3)\n",
            "Requirement already satisfied: cloudpickle<1.4.0,>=1.2.0 in /usr/local/lib/python3.6/dist-packages (from gym[Box_2D]) (1.3.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from gym[Box_2D]) (1.4.1)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from pyglet<=1.5.0,>=1.4.0->gym[Box_2D]) (0.16.0)\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "x11-utils is already the newest version (7.7+3build1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 25 not upgraded.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<Display cmd_param=['Xvfb', '-br', '-nolisten', 'tcp', '-screen', '0', '400x300x24', ':1001'] cmd=['Xvfb', '-br', '-nolisten', 'tcp', '-screen', '0', '400x300x24', ':1001'] oserror=None return_code=None stdout=\"None\" stderr=\"None\" timeout_happened=False>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pXRGfiEXXa0y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import gym\n",
        "import tensorflow as tf\n",
        "import tensorflow.nn as nn\n",
        "from tensorflow.keras import Model\n",
        "from tensorflow.keras.layers import Conv2D, Dense\n",
        "import tensorflow.keras.backend as K\n",
        "import tensorflow_probability as tfp\n",
        "from tensorflow.keras import optimizers\n",
        "from torch.distributions import Beta\n",
        "from torch.utils.data.sampler import BatchSampler, SubsetRandomSampler\n",
        "from tqdm.notebook import tqdm"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g60yuafaaupN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tf.keras.backend.clear_session()  # For easy reset of notebook state.\n",
        "tf.keras.backend.set_floatx('float64')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SLEgEe1CX_s7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "gamma = 0.99\n",
        "action_repeat = 8\n",
        "img_stack = 4\n",
        "seed = 0\n",
        "render = False\n",
        "log_interval = 10\n",
        "transition = np.dtype([('s', np.float64, (96, 96, img_stack)), ('a', np.float64, (3,)), ('a_logp', np.float64),\n",
        "                       ('r', np.float64), ('s_', np.float64, (96, 96, img_stack))])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L2DOV1s_Zziq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Env():\n",
        "    \"\"\"\n",
        "    Environment wrapper for CarRacing \n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        self.env = gym.make('CarRacing-v0')\n",
        "        self.env.seed(seed)\n",
        "        self.reward_threshold = self.env.spec.reward_threshold\n",
        "\n",
        "    def reset(self):\n",
        "        self.counter = 0\n",
        "        self.av_r = self.reward_memory()\n",
        "\n",
        "        self.die = False\n",
        "        img_rgb = self.env.reset()\n",
        "        img_gray = self.rgb2gray(img_rgb)\n",
        "        self.stack = [img_gray] * img_stack  # four frames for decision\n",
        "        return np.array(self.stack)\n",
        "\n",
        "    def step(self, action):\n",
        "        total_reward = 0\n",
        "        for i in range(action_repeat):\n",
        "            img_rgb, reward, die, _ = self.env.step(action)\n",
        "            # don't penalize \"die state\"\n",
        "            if die:\n",
        "                reward += 100\n",
        "            # green penalty\n",
        "            if np.mean(img_rgb[:, :, 1]) > 185.0:\n",
        "                reward -= 0.05\n",
        "            total_reward += reward\n",
        "            # if no reward recently, end the episode\n",
        "            done = True if self.av_r(reward) <= -0.1 else False\n",
        "            if done or die:\n",
        "                break\n",
        "        img_gray = self.rgb2gray(img_rgb)\n",
        "        self.stack.pop(0)\n",
        "        self.stack.append(img_gray)\n",
        "        assert len(self.stack) == img_stack\n",
        "        return np.array(self.stack), total_reward, done, die\n",
        "\n",
        "    def render(self, *arg):\n",
        "        self.env.render(*arg)\n",
        "\n",
        "    @staticmethod\n",
        "    def rgb2gray(rgb, norm=True):\n",
        "        # rgb image -> gray [0, 1]\n",
        "        gray = np.dot(rgb[..., :], [0.299, 0.587, 0.114])\n",
        "        if norm:\n",
        "            # normalize\n",
        "            gray = gray / 128. - 1.\n",
        "        return gray\n",
        "\n",
        "    @staticmethod\n",
        "    def reward_memory():\n",
        "        # record reward for last 100 steps\n",
        "        count = 0\n",
        "        length = 100\n",
        "        history = np.zeros(length)\n",
        "\n",
        "        def memory(reward):\n",
        "            nonlocal count\n",
        "            history[count] = reward\n",
        "            count = (count + 1) % length\n",
        "            return np.mean(history)\n",
        "\n",
        "        return memory"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l4EUyYXMaTye",
        "colab_type": "code",
        "outputId": "aeee2d6b-9142-4800-ffa3-7ad78c5a0f30",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 236
        }
      },
      "source": [
        "class Net(nn.Module):\n",
        "    \"\"\"\n",
        "    Actor-Critic Network for PPO\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.cnn_base = nn.Sequential(  # input shape (4, 96, 96)\n",
        "            nn.Conv2d(args.img_stack, 8, kernel_size=4, stride=2),\n",
        "            nn.ReLU(),  # activation\n",
        "            nn.Conv2d(8, 16, kernel_size=3, stride=2),  # (8, 47, 47)\n",
        "            nn.ReLU(),  # activation\n",
        "            nn.Conv2d(16, 32, kernel_size=3, stride=2),  # (16, 23, 23)\n",
        "            nn.ReLU(),  # activation\n",
        "            nn.Conv2d(32, 64, kernel_size=3, stride=2),  # (32, 11, 11)\n",
        "            nn.ReLU(),  # activation\n",
        "            nn.Conv2d(64, 128, kernel_size=3, stride=1),  # (64, 5, 5)\n",
        "            nn.ReLU(),  # activation\n",
        "            nn.Conv2d(128, 256, kernel_size=3, stride=1),  # (128, 3, 3)\n",
        "            nn.ReLU(),  # activation\n",
        "        )  # output shape (256, 1, 1)\n",
        "        self.v = nn.Sequential(nn.Linear(256, 100), nn.ReLU(), nn.Linear(100, 1))\n",
        "        self.fc = nn.Sequential(nn.Linear(256, 100), nn.ReLU())\n",
        "        self.alpha_head = nn.Sequential(nn.Linear(100, 3), nn.Softplus())\n",
        "        self.beta_head = nn.Sequential(nn.Linear(100, 3), nn.Softplus())\n",
        "        self.apply(self._weights_init)\n",
        "\n",
        "    @staticmethod\n",
        "    def _weights_init(m):\n",
        "        if isinstance(m, nn.Conv2d):\n",
        "            nn.init.xavier_uniform_(m.weight, gain=nn.init.calculate_gain('relu'))\n",
        "            nn.init.constant_(m.bias, 0.1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.cnn_base(x)\n",
        "        x = x.view(-1, 256)\n",
        "        v = self.v(x)\n",
        "        x = self.fc(x)\n",
        "        alpha = self.alpha_head(x) + 1\n",
        "        beta = self.beta_head(x) + 1\n",
        "\n",
        "        return (alpha, beta), v"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-70601e341aad>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mclass\u001b[0m \u001b[0mNet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModule\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \"\"\"\n\u001b[1;32m      3\u001b[0m     \u001b[0mActor\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mCritic\u001b[0m \u001b[0mNetwork\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mPPO\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \"\"\"\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: module 'tensorflow.nn' has no attribute 'Module'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0gE8ujOgbkTC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class ActorCriticModel(tf.keras.Model):\n",
        "    \"\"\"\n",
        "    Actor-Critic Network for PPO\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        super(ActorCriticModel, self).__init__()\n",
        "        self.cnn_base = tf.keras.Sequential() # # input shape (4, 96, 96)\n",
        "        self.cnn_base.add(Conv2D(8,kernel_size=4, strides=2, activation='relu', input_shape=(96, 96, 4),)) # data_format='channels_first'))\n",
        "        self.cnn_base.add(Conv2D(16,kernel_size=3, strides=2, activation='relu',)) #data_format='channels_first')) # (8, 47, 47) \n",
        "        self.cnn_base.add(Conv2D(32,kernel_size=3, strides=2, activation='relu',)) # data_format='channels_first')) # (16, 23, 23)\n",
        "        self.cnn_base.add(Conv2D(64,kernel_size=3, strides=2, activation='relu',)) # data_format='channels_first')) # (32, 11, 11)\n",
        "        self.cnn_base.add(Conv2D(128,kernel_size=3, strides=1, activation='relu',)) # data_format='channels_first')) # (64, 5, 5)\n",
        "        self.cnn_base.add(Conv2D(256,kernel_size=3, strides=1, activation='relu',)) # data_format='channels_first')) # (128, 3, 3)\n",
        "        # output shape (256, 1, 1)\n",
        "\n",
        "        print(self.cnn_base.summary())\n",
        "        self.v = tf.keras.Sequential([ # input shape 256\n",
        "          Dense(100,activation='relu',input_shape=(256,)),\n",
        "          Dense(1)\n",
        "        ])\n",
        "        self.fc = tf.keras.Sequential([ # input shape 256\n",
        "          Dense(100,input_shape=(256,))\n",
        "        ])\n",
        "        self.alpha_head = tf.keras.Sequential([ # input shape 100\n",
        "          Dense(3, activation='softplus', input_shape=(100,))\n",
        "        ])\n",
        "        self.beta_head = tf.keras.Sequential([ #input shape 100\n",
        "          Dense(3, activation='softplus', input_shape=(100,)),\n",
        "        ])\n",
        "        # self.apply(self._weights_init)\n",
        "\n",
        "    # @staticmethod\n",
        "    # def _weights_init(m):\n",
        "    #     if isinstance(m, nn.Conv2d):\n",
        "    #         nn.init.xavier_uniform_(m.weight, gain=nn.init.calculate_gain('relu'))\n",
        "    #         nn.init.constant_(m.bias, 0.1)\n",
        "\n",
        "    def call(self, x):\n",
        "        x = self.cnn_base(x)\n",
        "        # print(\"cnn_base:\",x.shape)\n",
        "        x = tf.reshape(x,[-1,256])\n",
        "        # x = tf.expand_dims(x,0)\n",
        "        # print(\"squeezed:\",x.shape)\n",
        "        v = self.v(x)\n",
        "        x = self.fc(x)\n",
        "        alpha = self.alpha_head(x) + 1\n",
        "        beta = self.beta_head(x) + 1\n",
        "        return (alpha, beta), v"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q8VGusH3h9uZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Agent():\n",
        "    \"\"\"\n",
        "    Agent for training\n",
        "    \"\"\"\n",
        "    max_grad_norm = 0.5\n",
        "    clip_param = 0.1  # epsilon in clipped loss\n",
        "    ppo_epoch = 10\n",
        "    buffer_capacity, batch_size = 150, 32 # 2000, 128\n",
        "\n",
        "    def __init__(self):\n",
        "        self.training_step = 0\n",
        "        self.net = ActorCriticModel()\n",
        "        self.buffer = np.empty(self.buffer_capacity, dtype=transition)\n",
        "        self.counter = 0\n",
        "\n",
        "        self.optimizer = optimizers.Adam(lr=1e-3)\n",
        "        self.loss = tf.keras.losses.Huber()\n",
        "        self.train_loss = tf.keras.metrics.Mean(name='train_loss')\n",
        "\n",
        "    def select_action(self, state):\n",
        "        # state = torch.from_numpy(state).double().to(device).unsqueeze(0)\n",
        "        # with torch.no_grad():\n",
        "        alpha, beta = self.net(state)[0]\n",
        "        dist = tfp.distributions.Beta(alpha, beta)\n",
        "        action = dist.sample()\n",
        "        a_logp = dist.log_prob(action)\n",
        "        a_logp = tf.reduce_sum(a_logp, axis=1)\n",
        "\n",
        "        action = tf.squeeze(action).numpy()\n",
        "        a_logp = a_logp.numpy()\n",
        "        return action, a_logp\n",
        "\n",
        "    def save_param(self):\n",
        "        torch.save(self.net.state_dict(), 'param/ppo_net_params.pkl')\n",
        "\n",
        "    def store(self, transition):\n",
        "        self.buffer[self.counter] = transition\n",
        "        self.counter += 1\n",
        "        if self.counter == self.buffer_capacity:\n",
        "            self.counter = 0\n",
        "            return True\n",
        "        else:\n",
        "            return False\n",
        "\n",
        "    def update2(self,):\n",
        "        self.training_step += 1\n",
        "\n",
        "        s = tf.constant(self.buffer['s'], dtype=tf.float64)\n",
        "        a = tf.constant(self.buffer['a'], dtype=tf.float64)\n",
        "        r = tf.constant(self.buffer['r'], dtype=tf.float64)\n",
        "        r = tf.reshape(r,(-1, 1))\n",
        "        s_ = tf.constant(self.buffer['s_'], dtype=tf.float64)\n",
        "\n",
        "        old_a_logp = tf.constant(self.buffer['a_logp'], dtype=tf.float64)#.to(device).view(-1, 1)\n",
        "        print(\"s shape:\",s.shape)\n",
        "        # with torch.no_grad():\n",
        "        target_v = r + gamma * self.net(s_)[1]\n",
        "        adv = target_v - self.net(s)[1]\n",
        "        # dataset = list(dataset)\n",
        "        dataset = tf.data.Dataset.from_tensor_slices({\"s\": s, \"a\": a, \"old_a_logp\": old_a_logp,\n",
        "                                                      \"target_v\":target_v, \"adv\":adv}).batch(self.batch_size).as_numpy_iterator()\n",
        "        dataset = list(dataset)\n",
        "        for _ in range(self.ppo_epoch):\n",
        "            for data in dataset: #BatchSampler(SubsetRandomSampler(range(self.buffer_capacity)), self.batch_size, False):\n",
        "                # print(\"Input shape1:\",s[index].shape)\n",
        "                s = data[\"s\"]\n",
        "                a = data[\"a\"]\n",
        "                old_a_logp = data[\"old_a_logp\"]\n",
        "                target_v = data[\"target_v\"]\n",
        "                adv = data[\"adv\"]\n",
        "                self.train_step2(s, a , old_a_logp, adv, target_v)\n",
        "\n",
        "    def train_step2(self,s, a, old_a_logp, adv, target_v):\n",
        "        with tf.GradientTape() as tape:\n",
        "            # training=True is only needed if there are layers with different\n",
        "            # behavior during training versus inference (e.g. Dropout).\n",
        "            s = tf.constant(s,dtype=tf.float64)\n",
        "            a = tf.constant(a,dtype=tf.float64)\n",
        "            old_a_logp = tf.constant(old_a_logp,dtype=tf.float64)\n",
        "            adv = tf.constant(adv,dtype=tf.float64)\n",
        "            target_v = tf.constant(target_v,dtype=tf.float64)\n",
        "            # print(\"Input shape:\",s.shape)\n",
        "\n",
        "            (alpha, beta), v = self.net(s)\n",
        "            dist = tfp.distributions.Beta(alpha, beta)\n",
        "            # a_logp = dist.log_prob(a).sum(axis=1, keepdim=True)\n",
        "            a_logp = dist.log_prob(a)\n",
        "            a_logp = tf.reduce_sum(a_logp, axis=1, keepdims=True)\n",
        "            \n",
        "            ratio = tf.math.exp(a_logp - old_a_logp)\n",
        "            surr1 = ratio * adv\n",
        "            surr2 = tf.clip_by_value(ratio, 1.0 - self.clip_param, 1.0 + self.clip_param) * adv\n",
        "            action_loss = tf.reduce_mean(-tf.math.minimum(surr1, surr2))\n",
        "            # print(\"v:\",v.dtype,\"target_v:\",target_v.dtype)\n",
        "            # print(\"v:\",type(v),\"target_v:\",type(target_v))\n",
        "            v = tf.squeeze(v)\n",
        "            target_v = tf.squeeze(target_v)\n",
        "            value_loss = self.loss(v, target_v)\n",
        "            # print(\"Action Loss:\",action_loss,\"Value Loss:\",value_loss)\n",
        "            loss = action_loss + 2. * value_loss\n",
        "            # loss = loss_object(labels, predictions)\n",
        "        gradients = tape.gradient(loss, self.net.trainable_variables)\n",
        "        self.optimizer.apply_gradients(zip(gradients, self.net.trainable_variables))\n",
        "        self.train_loss(loss)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3q6IKpS2pB9j",
        "colab_type": "code",
        "outputId": "7ea8f42e-bdc0-4711-dfb8-b7a3aa99cafd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "agent = Agent()\n",
        "env = Env()\n",
        "# if args.vis:\n",
        "#     draw_reward = DrawLine(env=\"car\", title=\"PPO\", xlabel=\"Episode\", ylabel=\"Moving averaged episode reward\")\n",
        "\n",
        "training_records = []\n",
        "running_score = 0\n",
        "state = env.reset()\n",
        "for i_ep in range(100000):\n",
        "    score = 0\n",
        "    state = env.reset()\n",
        "    state = np.moveaxis(state, 0, -1)\n",
        "    state = np.expand_dims(state, axis=0).astype(np.float64)\n",
        "    for t in range(1000):\n",
        "        # print(state.shape)\n",
        "        action, a_logp = agent.select_action(state)\n",
        "        state_, reward, done, die = env.step(action * np.array([2., 1., 1.]) + np.array([-1., 0., 0.]))\n",
        "        state_ = np.moveaxis(state_, 0, -1)\n",
        "        state_ = np.expand_dims(state_, axis=0).astype(np.float64)\n",
        "        if render:\n",
        "            env.render()\n",
        "        if agent.store((state, action, a_logp, reward, state_)):\n",
        "            print('updating')\n",
        "            # dataset = tf.data.Dataset.range(150).batch(32).as_numpy_iterator()\n",
        "            # dataset = list(dataset)\n",
        "            # agent.train_step(dataset)\n",
        "            agent.update2()\n",
        "        score += reward\n",
        "        state = state_\n",
        "        if done or die:\n",
        "            break\n",
        "    running_score = running_score * 0.99 + score * 0.01\n",
        "\n",
        "    if i_ep % log_interval == 0 or True:\n",
        "        # if args.vis:\n",
        "        #     draw_reward(xdata=i_ep, ydata=running_score)\n",
        "        loss = agent.train_loss.result()\n",
        "        print('Ep {}\\tLast score: {:.2f}\\tMoving average score: {:.2f}\\tLoss: {:.5f}'.format(i_ep, score, running_score, loss))\n",
        "        # agent.save_param()\n",
        "    if running_score > env.reward_threshold:\n",
        "        print(\"Solved! Running reward is now {} and the last episode runs to {}!\".format(running_score, score))\n",
        "        break"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_60\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_72 (Conv2D)           (None, 47, 47, 8)         520       \n",
            "_________________________________________________________________\n",
            "conv2d_73 (Conv2D)           (None, 23, 23, 16)        1168      \n",
            "_________________________________________________________________\n",
            "conv2d_74 (Conv2D)           (None, 11, 11, 32)        4640      \n",
            "_________________________________________________________________\n",
            "conv2d_75 (Conv2D)           (None, 5, 5, 64)          18496     \n",
            "_________________________________________________________________\n",
            "conv2d_76 (Conv2D)           (None, 3, 3, 128)         73856     \n",
            "_________________________________________________________________\n",
            "conv2d_77 (Conv2D)           (None, 1, 1, 256)         295168    \n",
            "=================================================================\n",
            "Total params: 393,848\n",
            "Trainable params: 393,848\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Track generation: 1143..1442 -> 299-tiles track\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
            "  warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Track generation: 1087..1369 -> 282-tiles track\n",
            "Ep 0\tLast score: 99.64\tMoving average score: 1.00\tLoss: 0.00000\n",
            "Track generation: 964..1212 -> 248-tiles track\n",
            "retry to generate track (normal if there are not many of this messages)\n",
            "Track generation: 1176..1474 -> 298-tiles track\n",
            "updating\n",
            "s shape: (150, 96, 96, 4)\n",
            "Input shape: (32, 96, 96, 4)\n",
            "v: <dtype: 'float64'> target_v: <dtype: 'float64'>\n",
            "v: <class 'tensorflow.python.framework.ops.EagerTensor'> target_v: <class 'tensorflow.python.framework.ops.EagerTensor'>\n",
            "Action Loss: tf.Tensor(0.034350731854293416, shape=(), dtype=float64) Value Loss: tf.Tensor(0.9159199595451355, shape=(), dtype=float64)\n",
            "Input shape: (32, 96, 96, 4)\n",
            "v: <dtype: 'float64'> target_v: <dtype: 'float64'>\n",
            "v: <class 'tensorflow.python.framework.ops.EagerTensor'> target_v: <class 'tensorflow.python.framework.ops.EagerTensor'>\n",
            "Action Loss: tf.Tensor(0.24088300420105646, shape=(), dtype=float64) Value Loss: tf.Tensor(0.7645790576934814, shape=(), dtype=float64)\n",
            "Input shape: (32, 96, 96, 4)\n",
            "v: <dtype: 'float64'> target_v: <dtype: 'float64'>\n",
            "v: <class 'tensorflow.python.framework.ops.EagerTensor'> target_v: <class 'tensorflow.python.framework.ops.EagerTensor'>\n",
            "Action Loss: tf.Tensor(0.5982711087385197, shape=(), dtype=float64) Value Loss: tf.Tensor(0.49050095677375793, shape=(), dtype=float64)\n",
            "Input shape: (32, 96, 96, 4)\n",
            "v: <dtype: 'float64'> target_v: <dtype: 'float64'>\n",
            "v: <class 'tensorflow.python.framework.ops.EagerTensor'> target_v: <class 'tensorflow.python.framework.ops.EagerTensor'>\n",
            "Action Loss: tf.Tensor(-2.309680238254435, shape=(), dtype=float64) Value Loss: tf.Tensor(3.9919378757476807, shape=(), dtype=float64)\n",
            "Input shape: (22, 96, 96, 4)\n",
            "v: <dtype: 'float64'> target_v: <dtype: 'float64'>\n",
            "v: <class 'tensorflow.python.framework.ops.EagerTensor'> target_v: <class 'tensorflow.python.framework.ops.EagerTensor'>\n",
            "Action Loss: tf.Tensor(0.7199871497584194, shape=(), dtype=float64) Value Loss: tf.Tensor(0.5043421387672424, shape=(), dtype=float64)\n",
            "Input shape: (32, 96, 96, 4)\n",
            "v: <dtype: 'float64'> target_v: <dtype: 'float64'>\n",
            "v: <class 'tensorflow.python.framework.ops.EagerTensor'> target_v: <class 'tensorflow.python.framework.ops.EagerTensor'>\n",
            "Action Loss: tf.Tensor(-0.01883927892021839, shape=(), dtype=float64) Value Loss: tf.Tensor(0.8391803503036499, shape=(), dtype=float64)\n",
            "Input shape: (32, 96, 96, 4)\n",
            "v: <dtype: 'float64'> target_v: <dtype: 'float64'>\n",
            "v: <class 'tensorflow.python.framework.ops.EagerTensor'> target_v: <class 'tensorflow.python.framework.ops.EagerTensor'>\n",
            "Action Loss: tf.Tensor(0.21660627676457755, shape=(), dtype=float64) Value Loss: tf.Tensor(0.7241507172584534, shape=(), dtype=float64)\n",
            "Input shape: (32, 96, 96, 4)\n",
            "v: <dtype: 'float64'> target_v: <dtype: 'float64'>\n",
            "v: <class 'tensorflow.python.framework.ops.EagerTensor'> target_v: <class 'tensorflow.python.framework.ops.EagerTensor'>\n",
            "Action Loss: tf.Tensor(0.5760164658672345, shape=(), dtype=float64) Value Loss: tf.Tensor(0.49389103055000305, shape=(), dtype=float64)\n",
            "Input shape: (32, 96, 96, 4)\n",
            "v: <dtype: 'float64'> target_v: <dtype: 'float64'>\n",
            "v: <class 'tensorflow.python.framework.ops.EagerTensor'> target_v: <class 'tensorflow.python.framework.ops.EagerTensor'>\n",
            "Action Loss: tf.Tensor(-3.0762133371040203, shape=(), dtype=float64) Value Loss: tf.Tensor(3.9049417972564697, shape=(), dtype=float64)\n",
            "Input shape: (22, 96, 96, 4)\n",
            "v: <dtype: 'float64'> target_v: <dtype: 'float64'>\n",
            "v: <class 'tensorflow.python.framework.ops.EagerTensor'> target_v: <class 'tensorflow.python.framework.ops.EagerTensor'>\n",
            "Action Loss: tf.Tensor(0.7397609105067273, shape=(), dtype=float64) Value Loss: tf.Tensor(0.520452618598938, shape=(), dtype=float64)\n",
            "Input shape: (32, 96, 96, 4)\n",
            "v: <dtype: 'float64'> target_v: <dtype: 'float64'>\n",
            "v: <class 'tensorflow.python.framework.ops.EagerTensor'> target_v: <class 'tensorflow.python.framework.ops.EagerTensor'>\n",
            "Action Loss: tf.Tensor(0.018077435197708783, shape=(), dtype=float64) Value Loss: tf.Tensor(0.8144742846488953, shape=(), dtype=float64)\n",
            "Input shape: (32, 96, 96, 4)\n",
            "v: <dtype: 'float64'> target_v: <dtype: 'float64'>\n",
            "v: <class 'tensorflow.python.framework.ops.EagerTensor'> target_v: <class 'tensorflow.python.framework.ops.EagerTensor'>\n",
            "Action Loss: tf.Tensor(0.22317347367949608, shape=(), dtype=float64) Value Loss: tf.Tensor(0.7240654230117798, shape=(), dtype=float64)\n",
            "Input shape: (32, 96, 96, 4)\n",
            "v: <dtype: 'float64'> target_v: <dtype: 'float64'>\n",
            "v: <class 'tensorflow.python.framework.ops.EagerTensor'> target_v: <class 'tensorflow.python.framework.ops.EagerTensor'>\n",
            "Action Loss: tf.Tensor(0.5624996675133721, shape=(), dtype=float64) Value Loss: tf.Tensor(0.46344301104545593, shape=(), dtype=float64)\n",
            "Input shape: (32, 96, 96, 4)\n",
            "v: <dtype: 'float64'> target_v: <dtype: 'float64'>\n",
            "v: <class 'tensorflow.python.framework.ops.EagerTensor'> target_v: <class 'tensorflow.python.framework.ops.EagerTensor'>\n",
            "Action Loss: tf.Tensor(-3.252102525399609, shape=(), dtype=float64) Value Loss: tf.Tensor(3.8982486724853516, shape=(), dtype=float64)\n",
            "Input shape: (22, 96, 96, 4)\n",
            "v: <dtype: 'float64'> target_v: <dtype: 'float64'>\n",
            "v: <class 'tensorflow.python.framework.ops.EagerTensor'> target_v: <class 'tensorflow.python.framework.ops.EagerTensor'>\n",
            "Action Loss: tf.Tensor(0.724134344066501, shape=(), dtype=float64) Value Loss: tf.Tensor(0.5059763193130493, shape=(), dtype=float64)\n",
            "Input shape: (32, 96, 96, 4)\n",
            "v: <dtype: 'float64'> target_v: <dtype: 'float64'>\n",
            "v: <class 'tensorflow.python.framework.ops.EagerTensor'> target_v: <class 'tensorflow.python.framework.ops.EagerTensor'>\n",
            "Action Loss: tf.Tensor(0.037212907804849205, shape=(), dtype=float64) Value Loss: tf.Tensor(0.7849641442298889, shape=(), dtype=float64)\n",
            "Input shape: (32, 96, 96, 4)\n",
            "v: <dtype: 'float64'> target_v: <dtype: 'float64'>\n",
            "v: <class 'tensorflow.python.framework.ops.EagerTensor'> target_v: <class 'tensorflow.python.framework.ops.EagerTensor'>\n",
            "Action Loss: tf.Tensor(0.21558665092608442, shape=(), dtype=float64) Value Loss: tf.Tensor(0.7272822856903076, shape=(), dtype=float64)\n",
            "Input shape: (32, 96, 96, 4)\n",
            "v: <dtype: 'float64'> target_v: <dtype: 'float64'>\n",
            "v: <class 'tensorflow.python.framework.ops.EagerTensor'> target_v: <class 'tensorflow.python.framework.ops.EagerTensor'>\n",
            "Action Loss: tf.Tensor(0.5453164419305974, shape=(), dtype=float64) Value Loss: tf.Tensor(0.4709450304508209, shape=(), dtype=float64)\n",
            "Input shape: (32, 96, 96, 4)\n",
            "v: <dtype: 'float64'> target_v: <dtype: 'float64'>\n",
            "v: <class 'tensorflow.python.framework.ops.EagerTensor'> target_v: <class 'tensorflow.python.framework.ops.EagerTensor'>\n",
            "Action Loss: tf.Tensor(-3.2801702872524636, shape=(), dtype=float64) Value Loss: tf.Tensor(3.8633878231048584, shape=(), dtype=float64)\n",
            "Input shape: (22, 96, 96, 4)\n",
            "v: <dtype: 'float64'> target_v: <dtype: 'float64'>\n",
            "v: <class 'tensorflow.python.framework.ops.EagerTensor'> target_v: <class 'tensorflow.python.framework.ops.EagerTensor'>\n",
            "Action Loss: tf.Tensor(0.6827987779184925, shape=(), dtype=float64) Value Loss: tf.Tensor(0.5101175904273987, shape=(), dtype=float64)\n",
            "Input shape: (32, 96, 96, 4)\n",
            "v: <dtype: 'float64'> target_v: <dtype: 'float64'>\n",
            "v: <class 'tensorflow.python.framework.ops.EagerTensor'> target_v: <class 'tensorflow.python.framework.ops.EagerTensor'>\n",
            "Action Loss: tf.Tensor(0.026529791036725127, shape=(), dtype=float64) Value Loss: tf.Tensor(0.7257576584815979, shape=(), dtype=float64)\n",
            "Input shape: (32, 96, 96, 4)\n",
            "v: <dtype: 'float64'> target_v: <dtype: 'float64'>\n",
            "v: <class 'tensorflow.python.framework.ops.EagerTensor'> target_v: <class 'tensorflow.python.framework.ops.EagerTensor'>\n",
            "Action Loss: tf.Tensor(0.19557744295138316, shape=(), dtype=float64) Value Loss: tf.Tensor(0.7293810844421387, shape=(), dtype=float64)\n",
            "Input shape: (32, 96, 96, 4)\n",
            "v: <dtype: 'float64'> target_v: <dtype: 'float64'>\n",
            "v: <class 'tensorflow.python.framework.ops.EagerTensor'> target_v: <class 'tensorflow.python.framework.ops.EagerTensor'>\n",
            "Action Loss: tf.Tensor(0.5226654194960666, shape=(), dtype=float64) Value Loss: tf.Tensor(0.4617786109447479, shape=(), dtype=float64)\n",
            "Input shape: (32, 96, 96, 4)\n",
            "v: <dtype: 'float64'> target_v: <dtype: 'float64'>\n",
            "v: <class 'tensorflow.python.framework.ops.EagerTensor'> target_v: <class 'tensorflow.python.framework.ops.EagerTensor'>\n",
            "Action Loss: tf.Tensor(-3.24355750265658, shape=(), dtype=float64) Value Loss: tf.Tensor(3.805145025253296, shape=(), dtype=float64)\n",
            "Input shape: (22, 96, 96, 4)\n",
            "v: <dtype: 'float64'> target_v: <dtype: 'float64'>\n",
            "v: <class 'tensorflow.python.framework.ops.EagerTensor'> target_v: <class 'tensorflow.python.framework.ops.EagerTensor'>\n",
            "Action Loss: tf.Tensor(0.6246875002752945, shape=(), dtype=float64) Value Loss: tf.Tensor(0.49706903100013733, shape=(), dtype=float64)\n",
            "Input shape: (32, 96, 96, 4)\n",
            "v: <dtype: 'float64'> target_v: <dtype: 'float64'>\n",
            "v: <class 'tensorflow.python.framework.ops.EagerTensor'> target_v: <class 'tensorflow.python.framework.ops.EagerTensor'>\n",
            "Action Loss: tf.Tensor(0.0224837355242061, shape=(), dtype=float64) Value Loss: tf.Tensor(0.7140868306159973, shape=(), dtype=float64)\n",
            "Input shape: (32, 96, 96, 4)\n",
            "v: <dtype: 'float64'> target_v: <dtype: 'float64'>\n",
            "v: <class 'tensorflow.python.framework.ops.EagerTensor'> target_v: <class 'tensorflow.python.framework.ops.EagerTensor'>\n",
            "Action Loss: tf.Tensor(0.17402476572740078, shape=(), dtype=float64) Value Loss: tf.Tensor(0.7256021499633789, shape=(), dtype=float64)\n",
            "Input shape: (32, 96, 96, 4)\n",
            "v: <dtype: 'float64'> target_v: <dtype: 'float64'>\n",
            "v: <class 'tensorflow.python.framework.ops.EagerTensor'> target_v: <class 'tensorflow.python.framework.ops.EagerTensor'>\n",
            "Action Loss: tf.Tensor(0.5263452243690635, shape=(), dtype=float64) Value Loss: tf.Tensor(0.4625281095504761, shape=(), dtype=float64)\n",
            "Input shape: (32, 96, 96, 4)\n",
            "v: <dtype: 'float64'> target_v: <dtype: 'float64'>\n",
            "v: <class 'tensorflow.python.framework.ops.EagerTensor'> target_v: <class 'tensorflow.python.framework.ops.EagerTensor'>\n",
            "Action Loss: tf.Tensor(-3.267023780766528, shape=(), dtype=float64) Value Loss: tf.Tensor(3.802976131439209, shape=(), dtype=float64)\n",
            "Input shape: (22, 96, 96, 4)\n",
            "v: <dtype: 'float64'> target_v: <dtype: 'float64'>\n",
            "v: <class 'tensorflow.python.framework.ops.EagerTensor'> target_v: <class 'tensorflow.python.framework.ops.EagerTensor'>\n",
            "Action Loss: tf.Tensor(0.625929196332012, shape=(), dtype=float64) Value Loss: tf.Tensor(0.49890410900115967, shape=(), dtype=float64)\n",
            "Input shape: (32, 96, 96, 4)\n",
            "v: <dtype: 'float64'> target_v: <dtype: 'float64'>\n",
            "v: <class 'tensorflow.python.framework.ops.EagerTensor'> target_v: <class 'tensorflow.python.framework.ops.EagerTensor'>\n",
            "Action Loss: tf.Tensor(-0.039089058864776156, shape=(), dtype=float64) Value Loss: tf.Tensor(0.6716617941856384, shape=(), dtype=float64)\n",
            "Input shape: (32, 96, 96, 4)\n",
            "v: <dtype: 'float64'> target_v: <dtype: 'float64'>\n",
            "v: <class 'tensorflow.python.framework.ops.EagerTensor'> target_v: <class 'tensorflow.python.framework.ops.EagerTensor'>\n",
            "Action Loss: tf.Tensor(0.17005487933372643, shape=(), dtype=float64) Value Loss: tf.Tensor(0.7220229506492615, shape=(), dtype=float64)\n",
            "Input shape: (32, 96, 96, 4)\n",
            "v: <dtype: 'float64'> target_v: <dtype: 'float64'>\n",
            "v: <class 'tensorflow.python.framework.ops.EagerTensor'> target_v: <class 'tensorflow.python.framework.ops.EagerTensor'>\n",
            "Action Loss: tf.Tensor(0.5395882020915262, shape=(), dtype=float64) Value Loss: tf.Tensor(0.4741916358470917, shape=(), dtype=float64)\n",
            "Input shape: (32, 96, 96, 4)\n",
            "v: <dtype: 'float64'> target_v: <dtype: 'float64'>\n",
            "v: <class 'tensorflow.python.framework.ops.EagerTensor'> target_v: <class 'tensorflow.python.framework.ops.EagerTensor'>\n",
            "Action Loss: tf.Tensor(-3.249118659462092, shape=(), dtype=float64) Value Loss: tf.Tensor(3.7920403480529785, shape=(), dtype=float64)\n",
            "Input shape: (22, 96, 96, 4)\n",
            "v: <dtype: 'float64'> target_v: <dtype: 'float64'>\n",
            "v: <class 'tensorflow.python.framework.ops.EagerTensor'> target_v: <class 'tensorflow.python.framework.ops.EagerTensor'>\n",
            "Action Loss: tf.Tensor(0.5993157875645451, shape=(), dtype=float64) Value Loss: tf.Tensor(0.4961547255516052, shape=(), dtype=float64)\n",
            "Input shape: (32, 96, 96, 4)\n",
            "v: <dtype: 'float64'> target_v: <dtype: 'float64'>\n",
            "v: <class 'tensorflow.python.framework.ops.EagerTensor'> target_v: <class 'tensorflow.python.framework.ops.EagerTensor'>\n",
            "Action Loss: tf.Tensor(-0.04526802939778526, shape=(), dtype=float64) Value Loss: tf.Tensor(0.6248446702957153, shape=(), dtype=float64)\n",
            "Input shape: (32, 96, 96, 4)\n",
            "v: <dtype: 'float64'> target_v: <dtype: 'float64'>\n",
            "v: <class 'tensorflow.python.framework.ops.EagerTensor'> target_v: <class 'tensorflow.python.framework.ops.EagerTensor'>\n",
            "Action Loss: tf.Tensor(0.14993470663338604, shape=(), dtype=float64) Value Loss: tf.Tensor(0.7243981957435608, shape=(), dtype=float64)\n",
            "Input shape: (32, 96, 96, 4)\n",
            "v: <dtype: 'float64'> target_v: <dtype: 'float64'>\n",
            "v: <class 'tensorflow.python.framework.ops.EagerTensor'> target_v: <class 'tensorflow.python.framework.ops.EagerTensor'>\n",
            "Action Loss: tf.Tensor(0.5338204812636038, shape=(), dtype=float64) Value Loss: tf.Tensor(0.4692460000514984, shape=(), dtype=float64)\n",
            "Input shape: (32, 96, 96, 4)\n",
            "v: <dtype: 'float64'> target_v: <dtype: 'float64'>\n",
            "v: <class 'tensorflow.python.framework.ops.EagerTensor'> target_v: <class 'tensorflow.python.framework.ops.EagerTensor'>\n",
            "Action Loss: tf.Tensor(-3.1870435751182598, shape=(), dtype=float64) Value Loss: tf.Tensor(3.7791318893432617, shape=(), dtype=float64)\n",
            "Input shape: (22, 96, 96, 4)\n",
            "v: <dtype: 'float64'> target_v: <dtype: 'float64'>\n",
            "v: <class 'tensorflow.python.framework.ops.EagerTensor'> target_v: <class 'tensorflow.python.framework.ops.EagerTensor'>\n",
            "Action Loss: tf.Tensor(0.5726147334794202, shape=(), dtype=float64) Value Loss: tf.Tensor(0.4978032112121582, shape=(), dtype=float64)\n",
            "Input shape: (32, 96, 96, 4)\n",
            "v: <dtype: 'float64'> target_v: <dtype: 'float64'>\n",
            "v: <class 'tensorflow.python.framework.ops.EagerTensor'> target_v: <class 'tensorflow.python.framework.ops.EagerTensor'>\n",
            "Action Loss: tf.Tensor(-0.04214156955761159, shape=(), dtype=float64) Value Loss: tf.Tensor(0.5965176224708557, shape=(), dtype=float64)\n",
            "Input shape: (32, 96, 96, 4)\n",
            "v: <dtype: 'float64'> target_v: <dtype: 'float64'>\n",
            "v: <class 'tensorflow.python.framework.ops.EagerTensor'> target_v: <class 'tensorflow.python.framework.ops.EagerTensor'>\n",
            "Action Loss: tf.Tensor(0.1590963845820114, shape=(), dtype=float64) Value Loss: tf.Tensor(0.7281939387321472, shape=(), dtype=float64)\n",
            "Input shape: (32, 96, 96, 4)\n",
            "v: <dtype: 'float64'> target_v: <dtype: 'float64'>\n",
            "v: <class 'tensorflow.python.framework.ops.EagerTensor'> target_v: <class 'tensorflow.python.framework.ops.EagerTensor'>\n",
            "Action Loss: tf.Tensor(0.541428586598905, shape=(), dtype=float64) Value Loss: tf.Tensor(0.4582689106464386, shape=(), dtype=float64)\n",
            "Input shape: (32, 96, 96, 4)\n",
            "v: <dtype: 'float64'> target_v: <dtype: 'float64'>\n",
            "v: <class 'tensorflow.python.framework.ops.EagerTensor'> target_v: <class 'tensorflow.python.framework.ops.EagerTensor'>\n",
            "Action Loss: tf.Tensor(-3.290049757263644, shape=(), dtype=float64) Value Loss: tf.Tensor(3.7992007732391357, shape=(), dtype=float64)\n",
            "Input shape: (22, 96, 96, 4)\n",
            "v: <dtype: 'float64'> target_v: <dtype: 'float64'>\n",
            "v: <class 'tensorflow.python.framework.ops.EagerTensor'> target_v: <class 'tensorflow.python.framework.ops.EagerTensor'>\n",
            "Action Loss: tf.Tensor(0.6137978053574354, shape=(), dtype=float64) Value Loss: tf.Tensor(0.5006200671195984, shape=(), dtype=float64)\n",
            "Input shape: (32, 96, 96, 4)\n",
            "v: <dtype: 'float64'> target_v: <dtype: 'float64'>\n",
            "v: <class 'tensorflow.python.framework.ops.EagerTensor'> target_v: <class 'tensorflow.python.framework.ops.EagerTensor'>\n",
            "Action Loss: tf.Tensor(-0.037869474884205015, shape=(), dtype=float64) Value Loss: tf.Tensor(0.6565036177635193, shape=(), dtype=float64)\n",
            "Input shape: (32, 96, 96, 4)\n",
            "v: <dtype: 'float64'> target_v: <dtype: 'float64'>\n",
            "v: <class 'tensorflow.python.framework.ops.EagerTensor'> target_v: <class 'tensorflow.python.framework.ops.EagerTensor'>\n",
            "Action Loss: tf.Tensor(0.16680183488401323, shape=(), dtype=float64) Value Loss: tf.Tensor(0.7186984419822693, shape=(), dtype=float64)\n",
            "Input shape: (32, 96, 96, 4)\n",
            "v: <dtype: 'float64'> target_v: <dtype: 'float64'>\n",
            "v: <class 'tensorflow.python.framework.ops.EagerTensor'> target_v: <class 'tensorflow.python.framework.ops.EagerTensor'>\n",
            "Action Loss: tf.Tensor(0.5365058318878269, shape=(), dtype=float64) Value Loss: tf.Tensor(0.4577920734882355, shape=(), dtype=float64)\n",
            "Input shape: (32, 96, 96, 4)\n",
            "v: <dtype: 'float64'> target_v: <dtype: 'float64'>\n",
            "v: <class 'tensorflow.python.framework.ops.EagerTensor'> target_v: <class 'tensorflow.python.framework.ops.EagerTensor'>\n",
            "Action Loss: tf.Tensor(-3.301387598527168, shape=(), dtype=float64) Value Loss: tf.Tensor(3.7729945182800293, shape=(), dtype=float64)\n",
            "Input shape: (22, 96, 96, 4)\n",
            "v: <dtype: 'float64'> target_v: <dtype: 'float64'>\n",
            "v: <class 'tensorflow.python.framework.ops.EagerTensor'> target_v: <class 'tensorflow.python.framework.ops.EagerTensor'>\n",
            "Action Loss: tf.Tensor(0.5875645948047021, shape=(), dtype=float64) Value Loss: tf.Tensor(0.4891341030597687, shape=(), dtype=float64)\n",
            "Ep 1\tLast score: -17.89\tMoving average score: 0.81\tLoss: 2.15830\n",
            "Track generation: 1283..1608 -> 325-tiles track\n",
            "updating\n",
            "s shape: (150, 96, 96, 4)\n",
            "Input shape: (32, 96, 96, 4)\n",
            "v: <dtype: 'float64'> target_v: <dtype: 'float64'>\n",
            "v: <class 'tensorflow.python.framework.ops.EagerTensor'> target_v: <class 'tensorflow.python.framework.ops.EagerTensor'>\n",
            "Action Loss: tf.Tensor(0.30859258765990427, shape=(), dtype=float64) Value Loss: tf.Tensor(0.6761120557785034, shape=(), dtype=float64)\n",
            "Input shape: (32, 96, 96, 4)\n",
            "v: <dtype: 'float64'> target_v: <dtype: 'float64'>\n",
            "v: <class 'tensorflow.python.framework.ops.EagerTensor'> target_v: <class 'tensorflow.python.framework.ops.EagerTensor'>\n",
            "Action Loss: tf.Tensor(0.3461871793459938, shape=(), dtype=float64) Value Loss: tf.Tensor(0.5662958025932312, shape=(), dtype=float64)\n",
            "Input shape: (32, 96, 96, 4)\n",
            "v: <dtype: 'float64'> target_v: <dtype: 'float64'>\n",
            "v: <class 'tensorflow.python.framework.ops.EagerTensor'> target_v: <class 'tensorflow.python.framework.ops.EagerTensor'>\n",
            "Action Loss: tf.Tensor(0.6560689236846818, shape=(), dtype=float64) Value Loss: tf.Tensor(0.23940683901309967, shape=(), dtype=float64)\n",
            "Input shape: (32, 96, 96, 4)\n",
            "v: <dtype: 'float64'> target_v: <dtype: 'float64'>\n",
            "v: <class 'tensorflow.python.framework.ops.EagerTensor'> target_v: <class 'tensorflow.python.framework.ops.EagerTensor'>\n",
            "Action Loss: tf.Tensor(0.1420468498822161, shape=(), dtype=float64) Value Loss: tf.Tensor(0.9291724562644958, shape=(), dtype=float64)\n",
            "Input shape: (22, 96, 96, 4)\n",
            "v: <dtype: 'float64'> target_v: <dtype: 'float64'>\n",
            "v: <class 'tensorflow.python.framework.ops.EagerTensor'> target_v: <class 'tensorflow.python.framework.ops.EagerTensor'>\n",
            "Action Loss: tf.Tensor(0.42292880104360453, shape=(), dtype=float64) Value Loss: tf.Tensor(0.5355530381202698, shape=(), dtype=float64)\n",
            "Input shape: (32, 96, 96, 4)\n",
            "v: <dtype: 'float64'> target_v: <dtype: 'float64'>\n",
            "v: <class 'tensorflow.python.framework.ops.EagerTensor'> target_v: <class 'tensorflow.python.framework.ops.EagerTensor'>\n",
            "Action Loss: tf.Tensor(0.25975475119076585, shape=(), dtype=float64) Value Loss: tf.Tensor(0.5806111693382263, shape=(), dtype=float64)\n",
            "Input shape: (32, 96, 96, 4)\n",
            "v: <dtype: 'float64'> target_v: <dtype: 'float64'>\n",
            "v: <class 'tensorflow.python.framework.ops.EagerTensor'> target_v: <class 'tensorflow.python.framework.ops.EagerTensor'>\n",
            "Action Loss: tf.Tensor(0.2873915910624627, shape=(), dtype=float64) Value Loss: tf.Tensor(0.5505239367485046, shape=(), dtype=float64)\n",
            "Input shape: (32, 96, 96, 4)\n",
            "v: <dtype: 'float64'> target_v: <dtype: 'float64'>\n",
            "v: <class 'tensorflow.python.framework.ops.EagerTensor'> target_v: <class 'tensorflow.python.framework.ops.EagerTensor'>\n",
            "Action Loss: tf.Tensor(0.6283578754949668, shape=(), dtype=float64) Value Loss: tf.Tensor(0.3887926936149597, shape=(), dtype=float64)\n",
            "Input shape: (32, 96, 96, 4)\n",
            "v: <dtype: 'float64'> target_v: <dtype: 'float64'>\n",
            "v: <class 'tensorflow.python.framework.ops.EagerTensor'> target_v: <class 'tensorflow.python.framework.ops.EagerTensor'>\n",
            "Action Loss: tf.Tensor(0.1538883344124402, shape=(), dtype=float64) Value Loss: tf.Tensor(0.722895622253418, shape=(), dtype=float64)\n",
            "Input shape: (22, 96, 96, 4)\n",
            "v: <dtype: 'float64'> target_v: <dtype: 'float64'>\n",
            "v: <class 'tensorflow.python.framework.ops.EagerTensor'> target_v: <class 'tensorflow.python.framework.ops.EagerTensor'>\n",
            "Action Loss: tf.Tensor(0.42975547218323107, shape=(), dtype=float64) Value Loss: tf.Tensor(0.5573492050170898, shape=(), dtype=float64)\n",
            "Input shape: (32, 96, 96, 4)\n",
            "v: <dtype: 'float64'> target_v: <dtype: 'float64'>\n",
            "v: <class 'tensorflow.python.framework.ops.EagerTensor'> target_v: <class 'tensorflow.python.framework.ops.EagerTensor'>\n",
            "Action Loss: tf.Tensor(0.2489054868022828, shape=(), dtype=float64) Value Loss: tf.Tensor(0.6063562035560608, shape=(), dtype=float64)\n",
            "Input shape: (32, 96, 96, 4)\n",
            "v: <dtype: 'float64'> target_v: <dtype: 'float64'>\n",
            "v: <class 'tensorflow.python.framework.ops.EagerTensor'> target_v: <class 'tensorflow.python.framework.ops.EagerTensor'>\n",
            "Action Loss: tf.Tensor(0.2780513541974555, shape=(), dtype=float64) Value Loss: tf.Tensor(0.5181422233581543, shape=(), dtype=float64)\n",
            "Input shape: (32, 96, 96, 4)\n",
            "v: <dtype: 'float64'> target_v: <dtype: 'float64'>\n",
            "v: <class 'tensorflow.python.framework.ops.EagerTensor'> target_v: <class 'tensorflow.python.framework.ops.EagerTensor'>\n",
            "Action Loss: tf.Tensor(0.5934221516282796, shape=(), dtype=float64) Value Loss: tf.Tensor(0.26867547631263733, shape=(), dtype=float64)\n",
            "Input shape: (32, 96, 96, 4)\n",
            "v: <dtype: 'float64'> target_v: <dtype: 'float64'>\n",
            "v: <class 'tensorflow.python.framework.ops.EagerTensor'> target_v: <class 'tensorflow.python.framework.ops.EagerTensor'>\n",
            "Action Loss: tf.Tensor(0.13475853868473744, shape=(), dtype=float64) Value Loss: tf.Tensor(0.6769202351570129, shape=(), dtype=float64)\n",
            "Input shape: (22, 96, 96, 4)\n",
            "v: <dtype: 'float64'> target_v: <dtype: 'float64'>\n",
            "v: <class 'tensorflow.python.framework.ops.EagerTensor'> target_v: <class 'tensorflow.python.framework.ops.EagerTensor'>\n",
            "Action Loss: tf.Tensor(0.3971491857419753, shape=(), dtype=float64) Value Loss: tf.Tensor(0.5049504041671753, shape=(), dtype=float64)\n",
            "Input shape: (32, 96, 96, 4)\n",
            "v: <dtype: 'float64'> target_v: <dtype: 'float64'>\n",
            "v: <class 'tensorflow.python.framework.ops.EagerTensor'> target_v: <class 'tensorflow.python.framework.ops.EagerTensor'>\n",
            "Action Loss: tf.Tensor(0.22491146672856008, shape=(), dtype=float64) Value Loss: tf.Tensor(0.5996742248535156, shape=(), dtype=float64)\n",
            "Input shape: (32, 96, 96, 4)\n",
            "v: <dtype: 'float64'> target_v: <dtype: 'float64'>\n",
            "v: <class 'tensorflow.python.framework.ops.EagerTensor'> target_v: <class 'tensorflow.python.framework.ops.EagerTensor'>\n",
            "Action Loss: tf.Tensor(0.28795511091485565, shape=(), dtype=float64) Value Loss: tf.Tensor(0.5196036100387573, shape=(), dtype=float64)\n",
            "Input shape: (32, 96, 96, 4)\n",
            "v: <dtype: 'float64'> target_v: <dtype: 'float64'>\n",
            "v: <class 'tensorflow.python.framework.ops.EagerTensor'> target_v: <class 'tensorflow.python.framework.ops.EagerTensor'>\n",
            "Action Loss: tf.Tensor(0.5948373688781553, shape=(), dtype=float64) Value Loss: tf.Tensor(0.24935118854045868, shape=(), dtype=float64)\n",
            "Input shape: (32, 96, 96, 4)\n",
            "v: <dtype: 'float64'> target_v: <dtype: 'float64'>\n",
            "v: <class 'tensorflow.python.framework.ops.EagerTensor'> target_v: <class 'tensorflow.python.framework.ops.EagerTensor'>\n",
            "Action Loss: tf.Tensor(0.13205573510669605, shape=(), dtype=float64) Value Loss: tf.Tensor(0.6214896440505981, shape=(), dtype=float64)\n",
            "Input shape: (22, 96, 96, 4)\n",
            "v: <dtype: 'float64'> target_v: <dtype: 'float64'>\n",
            "v: <class 'tensorflow.python.framework.ops.EagerTensor'> target_v: <class 'tensorflow.python.framework.ops.EagerTensor'>\n",
            "Action Loss: tf.Tensor(0.39862587857791304, shape=(), dtype=float64) Value Loss: tf.Tensor(0.45431143045425415, shape=(), dtype=float64)\n",
            "Input shape: (32, 96, 96, 4)\n",
            "v: <dtype: 'float64'> target_v: <dtype: 'float64'>\n",
            "v: <class 'tensorflow.python.framework.ops.EagerTensor'> target_v: <class 'tensorflow.python.framework.ops.EagerTensor'>\n",
            "Action Loss: tf.Tensor(0.2212836224096016, shape=(), dtype=float64) Value Loss: tf.Tensor(0.5925151109695435, shape=(), dtype=float64)\n",
            "Input shape: (32, 96, 96, 4)\n",
            "v: <dtype: 'float64'> target_v: <dtype: 'float64'>\n",
            "v: <class 'tensorflow.python.framework.ops.EagerTensor'> target_v: <class 'tensorflow.python.framework.ops.EagerTensor'>\n",
            "Action Loss: tf.Tensor(0.28781575370780355, shape=(), dtype=float64) Value Loss: tf.Tensor(0.5160094499588013, shape=(), dtype=float64)\n",
            "Input shape: (32, 96, 96, 4)\n",
            "v: <dtype: 'float64'> target_v: <dtype: 'float64'>\n",
            "v: <class 'tensorflow.python.framework.ops.EagerTensor'> target_v: <class 'tensorflow.python.framework.ops.EagerTensor'>\n",
            "Action Loss: tf.Tensor(0.5727703728018825, shape=(), dtype=float64) Value Loss: tf.Tensor(0.3262616693973541, shape=(), dtype=float64)\n",
            "Input shape: (32, 96, 96, 4)\n",
            "v: <dtype: 'float64'> target_v: <dtype: 'float64'>\n",
            "v: <class 'tensorflow.python.framework.ops.EagerTensor'> target_v: <class 'tensorflow.python.framework.ops.EagerTensor'>\n",
            "Action Loss: tf.Tensor(0.12939254278319318, shape=(), dtype=float64) Value Loss: tf.Tensor(0.6166317462921143, shape=(), dtype=float64)\n",
            "Input shape: (22, 96, 96, 4)\n",
            "v: <dtype: 'float64'> target_v: <dtype: 'float64'>\n",
            "v: <class 'tensorflow.python.framework.ops.EagerTensor'> target_v: <class 'tensorflow.python.framework.ops.EagerTensor'>\n",
            "Action Loss: tf.Tensor(0.38834388461664077, shape=(), dtype=float64) Value Loss: tf.Tensor(0.4539893567562103, shape=(), dtype=float64)\n",
            "Input shape: (32, 96, 96, 4)\n",
            "v: <dtype: 'float64'> target_v: <dtype: 'float64'>\n",
            "v: <class 'tensorflow.python.framework.ops.EagerTensor'> target_v: <class 'tensorflow.python.framework.ops.EagerTensor'>\n",
            "Action Loss: tf.Tensor(0.21176423822705337, shape=(), dtype=float64) Value Loss: tf.Tensor(0.5874724984169006, shape=(), dtype=float64)\n",
            "Input shape: (32, 96, 96, 4)\n",
            "v: <dtype: 'float64'> target_v: <dtype: 'float64'>\n",
            "v: <class 'tensorflow.python.framework.ops.EagerTensor'> target_v: <class 'tensorflow.python.framework.ops.EagerTensor'>\n",
            "Action Loss: tf.Tensor(0.2867921509901725, shape=(), dtype=float64) Value Loss: tf.Tensor(0.528830349445343, shape=(), dtype=float64)\n",
            "Input shape: (32, 96, 96, 4)\n",
            "v: <dtype: 'float64'> target_v: <dtype: 'float64'>\n",
            "v: <class 'tensorflow.python.framework.ops.EagerTensor'> target_v: <class 'tensorflow.python.framework.ops.EagerTensor'>\n",
            "Action Loss: tf.Tensor(0.5653460510872444, shape=(), dtype=float64) Value Loss: tf.Tensor(0.21322810649871826, shape=(), dtype=float64)\n",
            "Input shape: (32, 96, 96, 4)\n",
            "v: <dtype: 'float64'> target_v: <dtype: 'float64'>\n",
            "v: <class 'tensorflow.python.framework.ops.EagerTensor'> target_v: <class 'tensorflow.python.framework.ops.EagerTensor'>\n",
            "Action Loss: tf.Tensor(0.12776487647816456, shape=(), dtype=float64) Value Loss: tf.Tensor(0.6175437569618225, shape=(), dtype=float64)\n",
            "Input shape: (22, 96, 96, 4)\n",
            "v: <dtype: 'float64'> target_v: <dtype: 'float64'>\n",
            "v: <class 'tensorflow.python.framework.ops.EagerTensor'> target_v: <class 'tensorflow.python.framework.ops.EagerTensor'>\n",
            "Action Loss: tf.Tensor(0.3845885169985675, shape=(), dtype=float64) Value Loss: tf.Tensor(0.4514174163341522, shape=(), dtype=float64)\n",
            "Input shape: (32, 96, 96, 4)\n",
            "v: <dtype: 'float64'> target_v: <dtype: 'float64'>\n",
            "v: <class 'tensorflow.python.framework.ops.EagerTensor'> target_v: <class 'tensorflow.python.framework.ops.EagerTensor'>\n",
            "Action Loss: tf.Tensor(0.2101173079061004, shape=(), dtype=float64) Value Loss: tf.Tensor(0.5865339636802673, shape=(), dtype=float64)\n",
            "Input shape: (32, 96, 96, 4)\n",
            "v: <dtype: 'float64'> target_v: <dtype: 'float64'>\n",
            "v: <class 'tensorflow.python.framework.ops.EagerTensor'> target_v: <class 'tensorflow.python.framework.ops.EagerTensor'>\n",
            "Action Loss: tf.Tensor(0.2875168863065367, shape=(), dtype=float64) Value Loss: tf.Tensor(0.514624834060669, shape=(), dtype=float64)\n",
            "Input shape: (32, 96, 96, 4)\n",
            "v: <dtype: 'float64'> target_v: <dtype: 'float64'>\n",
            "v: <class 'tensorflow.python.framework.ops.EagerTensor'> target_v: <class 'tensorflow.python.framework.ops.EagerTensor'>\n",
            "Action Loss: tf.Tensor(0.5605980815320449, shape=(), dtype=float64) Value Loss: tf.Tensor(0.18984439969062805, shape=(), dtype=float64)\n",
            "Input shape: (32, 96, 96, 4)\n",
            "v: <dtype: 'float64'> target_v: <dtype: 'float64'>\n",
            "v: <class 'tensorflow.python.framework.ops.EagerTensor'> target_v: <class 'tensorflow.python.framework.ops.EagerTensor'>\n",
            "Action Loss: tf.Tensor(0.12852922128802574, shape=(), dtype=float64) Value Loss: tf.Tensor(0.6168520450592041, shape=(), dtype=float64)\n",
            "Input shape: (22, 96, 96, 4)\n",
            "v: <dtype: 'float64'> target_v: <dtype: 'float64'>\n",
            "v: <class 'tensorflow.python.framework.ops.EagerTensor'> target_v: <class 'tensorflow.python.framework.ops.EagerTensor'>\n",
            "Action Loss: tf.Tensor(0.3813243456197203, shape=(), dtype=float64) Value Loss: tf.Tensor(0.4502201974391937, shape=(), dtype=float64)\n",
            "Input shape: (32, 96, 96, 4)\n",
            "v: <dtype: 'float64'> target_v: <dtype: 'float64'>\n",
            "v: <class 'tensorflow.python.framework.ops.EagerTensor'> target_v: <class 'tensorflow.python.framework.ops.EagerTensor'>\n",
            "Action Loss: tf.Tensor(0.20715409588117134, shape=(), dtype=float64) Value Loss: tf.Tensor(0.5863808393478394, shape=(), dtype=float64)\n",
            "Input shape: (32, 96, 96, 4)\n",
            "v: <dtype: 'float64'> target_v: <dtype: 'float64'>\n",
            "v: <class 'tensorflow.python.framework.ops.EagerTensor'> target_v: <class 'tensorflow.python.framework.ops.EagerTensor'>\n",
            "Action Loss: tf.Tensor(0.2849166469977797, shape=(), dtype=float64) Value Loss: tf.Tensor(0.519723653793335, shape=(), dtype=float64)\n",
            "Input shape: (32, 96, 96, 4)\n",
            "v: <dtype: 'float64'> target_v: <dtype: 'float64'>\n",
            "v: <class 'tensorflow.python.framework.ops.EagerTensor'> target_v: <class 'tensorflow.python.framework.ops.EagerTensor'>\n",
            "Action Loss: tf.Tensor(0.5503041739673225, shape=(), dtype=float64) Value Loss: tf.Tensor(0.2740074694156647, shape=(), dtype=float64)\n",
            "Input shape: (32, 96, 96, 4)\n",
            "v: <dtype: 'float64'> target_v: <dtype: 'float64'>\n",
            "v: <class 'tensorflow.python.framework.ops.EagerTensor'> target_v: <class 'tensorflow.python.framework.ops.EagerTensor'>\n",
            "Action Loss: tf.Tensor(0.13066306523910087, shape=(), dtype=float64) Value Loss: tf.Tensor(0.6161743998527527, shape=(), dtype=float64)\n",
            "Input shape: (22, 96, 96, 4)\n",
            "v: <dtype: 'float64'> target_v: <dtype: 'float64'>\n",
            "v: <class 'tensorflow.python.framework.ops.EagerTensor'> target_v: <class 'tensorflow.python.framework.ops.EagerTensor'>\n",
            "Action Loss: tf.Tensor(0.379693319777526, shape=(), dtype=float64) Value Loss: tf.Tensor(0.4516778588294983, shape=(), dtype=float64)\n",
            "Input shape: (32, 96, 96, 4)\n",
            "v: <dtype: 'float64'> target_v: <dtype: 'float64'>\n",
            "v: <class 'tensorflow.python.framework.ops.EagerTensor'> target_v: <class 'tensorflow.python.framework.ops.EagerTensor'>\n",
            "Action Loss: tf.Tensor(0.20580076667051272, shape=(), dtype=float64) Value Loss: tf.Tensor(0.5925909876823425, shape=(), dtype=float64)\n",
            "Input shape: (32, 96, 96, 4)\n",
            "v: <dtype: 'float64'> target_v: <dtype: 'float64'>\n",
            "v: <class 'tensorflow.python.framework.ops.EagerTensor'> target_v: <class 'tensorflow.python.framework.ops.EagerTensor'>\n",
            "Action Loss: tf.Tensor(0.2892413079116923, shape=(), dtype=float64) Value Loss: tf.Tensor(0.5162339806556702, shape=(), dtype=float64)\n",
            "Input shape: (32, 96, 96, 4)\n",
            "v: <dtype: 'float64'> target_v: <dtype: 'float64'>\n",
            "v: <class 'tensorflow.python.framework.ops.EagerTensor'> target_v: <class 'tensorflow.python.framework.ops.EagerTensor'>\n",
            "Action Loss: tf.Tensor(0.5529822276303471, shape=(), dtype=float64) Value Loss: tf.Tensor(0.19598640501499176, shape=(), dtype=float64)\n",
            "Input shape: (32, 96, 96, 4)\n",
            "v: <dtype: 'float64'> target_v: <dtype: 'float64'>\n",
            "v: <class 'tensorflow.python.framework.ops.EagerTensor'> target_v: <class 'tensorflow.python.framework.ops.EagerTensor'>\n",
            "Action Loss: tf.Tensor(0.12944452745953883, shape=(), dtype=float64) Value Loss: tf.Tensor(0.6157106757164001, shape=(), dtype=float64)\n",
            "Input shape: (22, 96, 96, 4)\n",
            "v: <dtype: 'float64'> target_v: <dtype: 'float64'>\n",
            "v: <class 'tensorflow.python.framework.ops.EagerTensor'> target_v: <class 'tensorflow.python.framework.ops.EagerTensor'>\n",
            "Action Loss: tf.Tensor(0.3771989662658806, shape=(), dtype=float64) Value Loss: tf.Tensor(0.44995981454849243, shape=(), dtype=float64)\n",
            "Input shape: (32, 96, 96, 4)\n",
            "v: <dtype: 'float64'> target_v: <dtype: 'float64'>\n",
            "v: <class 'tensorflow.python.framework.ops.EagerTensor'> target_v: <class 'tensorflow.python.framework.ops.EagerTensor'>\n",
            "Action Loss: tf.Tensor(0.20391617463396353, shape=(), dtype=float64) Value Loss: tf.Tensor(0.586126446723938, shape=(), dtype=float64)\n",
            "Input shape: (32, 96, 96, 4)\n",
            "v: <dtype: 'float64'> target_v: <dtype: 'float64'>\n",
            "v: <class 'tensorflow.python.framework.ops.EagerTensor'> target_v: <class 'tensorflow.python.framework.ops.EagerTensor'>\n",
            "Action Loss: tf.Tensor(0.2884650481606634, shape=(), dtype=float64) Value Loss: tf.Tensor(0.5173581838607788, shape=(), dtype=float64)\n",
            "Input shape: (32, 96, 96, 4)\n",
            "v: <dtype: 'float64'> target_v: <dtype: 'float64'>\n",
            "v: <class 'tensorflow.python.framework.ops.EagerTensor'> target_v: <class 'tensorflow.python.framework.ops.EagerTensor'>\n",
            "Action Loss: tf.Tensor(0.5475809528046626, shape=(), dtype=float64) Value Loss: tf.Tensor(0.18109241127967834, shape=(), dtype=float64)\n",
            "Input shape: (32, 96, 96, 4)\n",
            "v: <dtype: 'float64'> target_v: <dtype: 'float64'>\n",
            "v: <class 'tensorflow.python.framework.ops.EagerTensor'> target_v: <class 'tensorflow.python.framework.ops.EagerTensor'>\n",
            "Action Loss: tf.Tensor(0.13036998092250265, shape=(), dtype=float64) Value Loss: tf.Tensor(0.6156743764877319, shape=(), dtype=float64)\n",
            "Input shape: (22, 96, 96, 4)\n",
            "v: <dtype: 'float64'> target_v: <dtype: 'float64'>\n",
            "v: <class 'tensorflow.python.framework.ops.EagerTensor'> target_v: <class 'tensorflow.python.framework.ops.EagerTensor'>\n",
            "Action Loss: tf.Tensor(0.3765224463339741, shape=(), dtype=float64) Value Loss: tf.Tensor(0.44919639825820923, shape=(), dtype=float64)\n",
            "Ep 2\tLast score: -20.71\tMoving average score: 0.59\tLoss: 1.74631\n",
            "Track generation: 1217..1526 -> 309-tiles track\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-36-f333b72b4a7e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0;31m# print(state.shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0maction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma_logp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect_action\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m         \u001b[0mstate_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdie\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2.\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1.\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1.\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1.\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m         \u001b[0mstate_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmoveaxis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0mstate_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand_dims\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-5-e8d6dd2d8355>\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0mtotal_reward\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction_repeat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m             \u001b[0mimg_rgb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdie\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m             \u001b[0;31m# don't penalize \"die state\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mdie\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/gym/wrappers/time_limit.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_elapsed_steps\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Cannot call env.step() before calling reset()\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m         \u001b[0mobservation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_elapsed_steps\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_elapsed_steps\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_max_episode_steps\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/gym/envs/box2d/car_racing.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m    321\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1.0\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mFPS\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    322\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 323\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrender\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"state_pixels\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    324\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    325\u001b[0m         \u001b[0mstep_reward\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/gym/envs/box2d/car_racing.py\u001b[0m in \u001b[0;36mrender\u001b[0;34m(self, mode)\u001b[0m\n\u001b[1;32m    392\u001b[0m         \u001b[0mgl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglViewport\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mVP_W\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mVP_H\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    393\u001b[0m         \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 394\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrender_road\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    395\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mgeom\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mviewer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0monetime_geoms\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    396\u001b[0m             \u001b[0mgeom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrender\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/gym/envs/box2d/car_racing.py\u001b[0m in \u001b[0;36mrender_road\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    433\u001b[0m             \u001b[0mgl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglColor4f\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolor\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolor\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolor\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    434\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpoly\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 435\u001b[0;31m                 \u001b[0mgl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglVertex3f\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    436\u001b[0m         \u001b[0mgl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglEnd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    437\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SkBwMr1TIEhu",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-qMdo2XGq2zf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}